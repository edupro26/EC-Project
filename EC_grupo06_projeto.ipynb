{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Engenharia do Conhecimento 2023/2024\n",
    "\n",
    "## Project: *Thyroid disease Data Set*\n",
    "\n",
    "#### Group 6:\n",
    "\n",
    "- Eduardo Proen√ßa 57551\n",
    "- Tiago Oliveira 54979\n",
    "- Bernardo Lopes 54386"
   ],
   "id": "37af115655e6ef16"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Summary\n",
    "\n",
    "1. Data Processing\n",
    "    1. Creating a Data Frame\n",
    "    2. Data investigation\n",
    "    3. Encoding Data\n",
    "    4. Splitting into training and testing set\n",
    "    5. Imputing missing values\n",
    "    6. Scaling Data\n",
    "    \n",
    "2. Classification Models\n",
    "    1. Feature Selection\n",
    "    2. Model evaluation\n",
    "    3. Decision Tree\n",
    "    4. Logistic Regression\n",
    "    5. Naive Bayes\n",
    "    6. KNN\n",
    "    7. SVM\n",
    "3. Hyperparameter tuning"
   ],
   "id": "8735b013813cf85e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Data Processing",
   "id": "7a3fe0f7bf074860"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1.1 Creating a Data Frame\n",
    "\n",
    "Firstly, we need to create a Data Frame. Using the [Pandas](https://pandas.pydata.org) Python Library, we can read our data from the file proj-data.csv, which contains the data set we will be using in this project."
   ],
   "id": "79a91cdf41098297"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data set\n",
    "df_thyroid = pd.read_csv('proj-data.csv')\n",
    "df_thyroid.shape"
   ],
   "id": "f2edb1e685a0e2d5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_thyroid.head()",
   "id": "3b1ab9a330192af9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.2 Data investigation",
   "id": "d58cfed3fb9fc2a3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for col in df_thyroid.columns:\n",
    "    print(\"Values of \", end='')\n",
    "    print(df_thyroid[col].value_counts(), end=\"\\n\\n\")"
   ],
   "id": "b917f0b00d08f6bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df = df_thyroid.drop(\"[record identification]\", axis=1)",
   "id": "a914a7b6fd7039d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "df.replace('?', np.nan, inplace=True)\n",
    "df.isna().sum()"
   ],
   "id": "6f21aa7626f43110",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_cleaned = (df.drop(\"TBG:\", axis = 1)).dropna(subset=[\"T3:\"])\n",
    "df_cleaned.info()"
   ],
   "id": "52483fdee69777d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.3 Encoding Data",
   "id": "b225a2e435e1a905"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "encoded_values = {\n",
    "    'M': '0', 'F': '1',\n",
    "    'f': '0', 't': '1'\n",
    "}\n",
    "target = \"diagnoses\"\n",
    "df_target = pd.DataFrame(df_cleaned[\"diagnoses\"], columns=[\"diagnoses\"])\n",
    "\n",
    "encoded = df_cleaned.drop(\"diagnoses\", axis=1).replace(encoded_values)\n",
    "df_encoded = pd.get_dummies(encoded, columns=[\"referral source:\"], dtype='int')"
   ],
   "id": "5c5d778d1a1a0927",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for index, value in df_target[target].items():\n",
    "    if value == '-':\n",
    "        df_target.at[index, target] = 0\n",
    "    elif value == 'A' or value == 'B' or value == 'C' or value == 'D':\n",
    "        df_target.at[index, target] = 1\n",
    "    elif value == 'E' or value == 'F' or value == 'G' or value == 'H':\n",
    "        df_target.at[index, target] = 2\n",
    "    elif value == 'I' or value == 'J':\n",
    "        df_target.at[index, target] = 3\n",
    "    elif value == 'K':\n",
    "        df_target.at[index, target] = 4\n",
    "    elif value == 'L' or value == 'M' or value == 'N':\n",
    "        df_target.at[index, target] = 5\n",
    "    elif value == 'O' or value == 'P' or value == 'Q':\n",
    "        df_target.at[index, target] = 6\n",
    "    elif value == 'R' or value == 'S' or value == 'T':\n",
    "        df_target.at[index, target] = 7\n",
    "    else:\n",
    "        df_target.at[index, target] = 8\n",
    "\n",
    "df_target[target] = pd.to_numeric(df_target[target])\n",
    "df_target[target].unique()"
   ],
   "id": "8bf89df76da8a4b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = pd.concat([df_encoded, df_target], axis=1)\n",
    "df.head()"
   ],
   "id": "ccac642a0fd480de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.4 Splitting into training and testing set",
   "id": "17c92ab69ddb4cab"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(\"diagnoses\", axis='columns')\n",
    "y = df[\"diagnoses\"]\n",
    "\n",
    "X_TRAIN, X_IVS, y_TRAIN, y_IVS = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "# Print the shapes of the training and testing sets\n",
    "print(\"Training set shape:\", X_TRAIN.shape, y_TRAIN.shape)\n",
    "print(\"Testing set shape:\", X_IVS.shape, y_IVS.shape)"
   ],
   "id": "84054ef19a46bc36",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.5 Imputing missing values",
   "id": "c3b56e64c29f54aa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f\"Missing values in training set: {X_TRAIN.isna().sum().sum()}\")\n",
    "print(f\"Missing values in testing set: {X_IVS.isna().sum().sum()}\")"
   ],
   "id": "9f8907a938e0da38",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Initialize KNNImputer with k=5 (you can adjust k as needed)\n",
    "imputer = KNNImputer(n_neighbors=3)\n",
    "\n",
    "# Perform KNN imputation\n",
    "X_train_imp = imputer.fit_transform(X_TRAIN)\n",
    "X_ivs_imp = imputer.transform(X_IVS)\n",
    "\n",
    "# Convert the imputed array back to a DataFrame\n",
    "train_nan = pd.DataFrame(X_train_imp, columns=X_TRAIN.columns).isna().sum().sum()\n",
    "ivs_nan = pd.DataFrame(X_ivs_imp, columns=X_IVS.columns).isna().sum().sum()\n",
    "\n",
    "print(f\"Missing values in training set: {train_nan}\")\n",
    "print(f\"Missing values in testing set: {ivs_nan}\")"
   ],
   "id": "e8524c87fdb9b95e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.6 Scaling Data",
   "id": "1bba58ad887007da"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_imp)\n",
    "\n",
    "X_train_scl = scaler.transform(X_train_imp)\n",
    "X_ivs_scl = scaler.transform(X_ivs_imp)\n",
    "\n",
    "pd.DataFrame(X_train_scl, columns = X_TRAIN.columns).head()"
   ],
   "id": "a380388d86699aa7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Classification Models",
   "id": "e70738c62e106345"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_TRAIN = X_train_scl\n",
    "X_IVS = X_ivs_scl\n",
    "y_TRAIN = y_TRAIN.to_numpy()\n",
    "y_IVS = y_IVS.to_numpy()"
   ],
   "id": "9b2fc4b3a38b4092",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.1 Feature Selection",
   "id": "b61e2db8481d56a2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TODO feature selection needs tuning\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "n_features = int(X_TRAIN.shape[1] * .4)\n",
    "sfs = SequentialFeatureSelector(LinearRegression(), \n",
    "                                n_features_to_select=5, \n",
    "                                direction='forward', \n",
    "                                n_jobs=-1)\n",
    "sfs.fit(X_TRAIN, y_TRAIN)\n",
    "\n",
    "N, M = X_TRAIN.shape\n",
    "features=sfs.get_support()\n",
    "features_selected = np.arange(M)[features]\n",
    "print(\"The features selected are columns: \", features_selected)\n",
    "\n",
    "X_TRAIN = sfs.transform(X_TRAIN)"
   ],
   "id": "34d5b40cf1d9af3b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.2 Model evaluation",
   "id": "4d1cd5a9bbb0f86b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "\n",
    "def evaluate(model):\n",
    "    TRUTH = None\n",
    "    PREDS = None\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=123)\n",
    "    for train_index, test_index in kf.split(X_TRAIN):\n",
    "        X_train, y_train = X_TRAIN[train_index], y_TRAIN[train_index]\n",
    "        X_test, y_test = X_TRAIN[test_index], y_TRAIN[test_index]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_test)\n",
    "        if TRUTH is None:\n",
    "            PREDS = preds\n",
    "            TRUTH = y_test\n",
    "        else:\n",
    "            PREDS = np.hstack((PREDS, preds))\n",
    "            TRUTH = np.hstack((TRUTH, y_test))\n",
    "    return TRUTH, PREDS\n",
    "            \n",
    "def print_statistics(truth, preds):\n",
    "    print(\"The Accuracy is: %7.4f\" % np.mean(accuracy_score(truth, preds)))\n",
    "    print(\"The Precision is: %7.4f\" % np.mean(precision_score(truth, preds, average='weighted', zero_division=1)))\n",
    "    print(\"The Recall is: %7.4f\" % np.mean(recall_score(truth, preds, average='weighted')))\n",
    "    print(\"The F1 score is: %7.4f\" % np.mean(f1_score(truth, preds, average='weighted')))\n",
    "    print(\"The Matthews correlation coefficient is: %7.4f\" % np.mean(matthews_corrcoef(truth, preds)))"
   ],
   "id": "dc8b24eb7dc939cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.3 Decision Tree",
   "id": "5218522c6999b051"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "TRUTH, PREDS = evaluate(DecisionTreeClassifier())\n",
    "print_statistics(TRUTH, PREDS)"
   ],
   "id": "35fbc3bb4a3abb37",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.4 Logistic Regression",
   "id": "6222832c15ef450a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "TRUTH, PREDS = evaluate(LogisticRegression())\n",
    "print_statistics(TRUTH, PREDS)"
   ],
   "id": "d1b1e8ca796dc518",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.5 Naive Bayes",
   "id": "ec2b6fbd3106cbfe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "TRUTH, PREDS = evaluate(GaussianNB())\n",
    "print_statistics(TRUTH, PREDS)"
   ],
   "id": "4ba343f74d834f9b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.6 KNN",
   "id": "f88c6db95ae0829e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "TRUTH, PREDS = evaluate(KNeighborsClassifier())\n",
    "print_statistics(TRUTH, PREDS)"
   ],
   "id": "9ca59f009dbf55eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.7 SVM",
   "id": "3af60905f986bb0c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# from sklearn.svm import SVC\n",
    "# \n",
    "# TRUTH, PREDS = evaluate(SVC(kernel = \"rbf\", C = 1, gamma = 0.1))\n",
    "# print_statistics(TRUTH, PREDS)"
   ],
   "id": "14e7bfa06b91c65a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Hyperparameter tuning",
   "id": "2eb5fadc77b4e4d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "scoring = [\"accuracy\", \"precision\", \"recall\", \"f1\"]",
   "id": "9f02ccc009a87b68",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "depths = [3, 5, 10, 15]\n",
    "m_sampl_split = [2, 5, 9]\n",
    "\n",
    "prune_a = [0.0, 0.0001, 0.001, 0.01]\n",
    "param_grid = {\n",
    "    'max_depth': depths,\n",
    "    'min_samples_split': m_sampl_split,\n",
    "    'ccp_alpha': prune_a\n",
    "}\n",
    "\n",
    "tree = DecisionTreeClassifier(criterion='log_loss', random_state=23)\n",
    "grid_search = GridSearchCV(tree, param_grid=param_grid, scoring=\"accuracy\", n_jobs=-1)\n",
    "grid_search.fit(X_TRAIN, y_TRAIN)\n",
    "\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)"
   ],
   "id": "1b126cf6adcb587b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# \n",
    "# param_grid = {\n",
    "#     \"n_neighbors\": [3, 4, 5, 6, 7, 9],\n",
    "#     \"weights\": [\"uniform\", \"distance\"]\n",
    "# }\n",
    "# \n",
    "# knn = KNeighborsClassifier()\n",
    "# grid_search = GridSearchCV(knn, param_grid = param_grid, cv = 5, scoring = \"f1\")\n",
    "# grid_search.fit(X_TRAIN, y_TRAIN)\n",
    "# \n",
    "# print(\"Best hyperparameters: \", grid_search.best_params_)"
   ],
   "id": "555cb4d343e354e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
