{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e47ecd3f7a7681a",
   "metadata": {},
   "source": [
    "# Engenharia do Conhecimento 2023/2024\n",
    "\n",
    "## Project: *Thyroid disease Data Set*\n",
    "\n",
    "#### Group 6:\n",
    "\n",
    "- Eduardo Proen√ßa 57551\n",
    "- Tiago Oliveira 54979\n",
    "- Bernardo Lopes 54386\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b41ecdb1cdb3f9",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "To be done..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f652d741ef14fc0",
   "metadata": {},
   "source": [
    "## 1. Data processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6609c1e4f2c7854",
   "metadata": {},
   "source": [
    "### 1.1 Creating a Data Frame\n",
    "\n",
    "Firstly, we need to create a Data Frame. Using the [Pandas](https://pandas.pydata.org) Python Library, we can read our data from the file proj-data.csv, which contains the data set we will be using in this project."
   ]
  },
  {
   "cell_type": "code",
   "id": "ff2b0f54da8e3a11",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data set\n",
    "df_thyroid = pd.read_csv('proj-data.csv')\n",
    "df_thyroid.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a6f5435c76fab441",
   "metadata": {},
   "source": [
    "df_thyroid.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.2 Data investigation",
   "id": "4a016ebe611ca03a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_thyroid.info()",
   "id": "3a5a2abac6b29bac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for col in df_thyroid.columns:\n",
    "    print(\"Values of \", end='')\n",
    "    print(df_thyroid[col].value_counts(), end=\"\\n\\n\")"
   ],
   "id": "972f648beb0eeca7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.3 Defining the train and target sets",
   "id": "12b9389aea7cd7fc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df = df_thyroid.drop(\"[record identification]\", axis = 1)",
   "id": "7ad763ecd1af3116",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X = df.drop(\"diagnoses\", axis='columns')\n",
    "y = df[\"diagnoses\"]"
   ],
   "id": "c9d97f580045cf89",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.4 Encoding our data",
   "id": "c7258171f85a871b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "encoded_values = {\n",
    "    'M': '0', 'F': '1',\n",
    "    'f': '0', 't': '1',\n",
    "    '?': np.NaN\n",
    "}\n",
    "\n",
    "X_encoded = pd.get_dummies(X.replace(encoded_values), \n",
    "                           columns=[\"referral source:\"], \n",
    "                           dtype='int')\n",
    "X_encoded.head()"
   ],
   "id": "da8539aa45ffafb9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_encoded = pd.get_dummies(y, dtype='int') # TODO needs a different encoding strategy \n",
    "y_encoded.head()"
   ],
   "id": "a6aed30e6c0a98dc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.5 Splitting",
   "id": "2fd74ac720283403"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = X_encoded\n",
    "y = y_encoded\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Print the shapes of the training and testing sets\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape, y_test.shape)"
   ],
   "id": "5c7ff18bc63416ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "ac5504eec79e3204"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.5 Imputation of missing values",
   "id": "b0925eb072502419"
  },
  {
   "cell_type": "code",
   "id": "8998bc869e6da132",
   "metadata": {},
   "source": [
    "X_train = X_train.drop(\"TBG:\", axis='columns')\n",
    "X_test = X_test.drop(\"TBG:\", axis='columns')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f05afa88d3fa8b95",
   "metadata": {},
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Initialize KNNImputer with k=5 (you can adjust k as needed)\n",
    "imputer = KNNImputer(n_neighbors=3)\n",
    "\n",
    "# Perform KNN imputation\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# Convert the imputed array back to a DataFrame\n",
    "X_train = pd.DataFrame(X_train_imputed, columns=X_train.columns)\n",
    "X_test = pd.DataFrame(X_test_imputed, columns=X_test.columns)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.6 Normalization",
   "id": "f63f1bfec86d42e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scl = scaler.transform(X_train)\n",
    "X_test_scl = scaler.transform(X_test)\n",
    "\n",
    "pd.DataFrame(X_train_scl, columns = X_train.columns).head()"
   ],
   "id": "ac697f942197163f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Classification Models",
   "id": "f95fe065b369236f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "\n",
    "def evaluate_model(model):\n",
    "    \"\"\"\n",
    "    Evaluate a single classification model.\n",
    "    \n",
    "    Args:\n",
    "    - model: A scikit-learn classification model object.\n",
    "    \n",
    "    Returns:\n",
    "    - metrics (dict): A dictionary containing evaluation metrics.\n",
    "    \"\"\"\n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train_scl, y_train)\n",
    "    \n",
    "    # Make predictions on the testing data\n",
    "    y_pred = model.predict(X_test_scl)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    #mcc = matthews_corrcoef(y_test, y_pred)\n",
    "    \n",
    "    # Print the evaluation metrics\n",
    "    print(f\"Model Evaluation Metrics:\")\n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall: {recall:.4f}\")\n",
    "    print(f\"  F1 Score: {f1:.4f}\")\n",
    "    #print(f\"  Matthews Correlation Coefficient: {mcc:.4f}\")\n",
    "    \n",
    "    # Store the evaluation metrics in a dictionary\n",
    "    metrics = {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1 Score\": f1,\n",
    "        #\"Matthews Correlation Coefficient\": mcc\n",
    "    }\n",
    "    \n",
    "    return metrics\n"
   ],
   "id": "251f126a8cebceb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "metrics = evaluate_model(DecisionTreeClassifier(max_depth = 5))"
   ],
   "id": "ac0343e8e08c11a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# \n",
    "# evaluate_model(LogisticRegression(penalty = \"l2\"))"
   ],
   "id": "18af00cbeaea0dce",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
